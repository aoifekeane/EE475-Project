{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multi_class_meter.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1cbuVHtlk8RLuqaZWylyLzUDpKtAqiHkO",
      "authorship_tag": "ABX9TyNS8mRXuKDbkgz0Rp1JT28H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aoifekeane/EE475-Project/blob/main/multi_class_meter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMdOwvcitJXH"
      },
      "source": [
        "#Multiclassifier for meter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKyMTyKItl4e"
      },
      "source": [
        "seed = 201715226"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXKy9HF9a2di"
      },
      "source": [
        "Random seed for consistency"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKQ8a5BhkIzO"
      },
      "source": [
        "lb = { 0: 'Hornpipes',\n",
        "      1: 'Jigs',\n",
        "      2: 'Reels', \n",
        "      3: 'Polkas',\n",
        "      4: 'Slides'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iC0l8S-ra7TC"
      },
      "source": [
        "Dictionary to convert label values to actual names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNsV7vt0-sov"
      },
      "source": [
        "import glob\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "img_height = 288\n",
        "img_width = 432\n",
        "\n",
        "hornpipe = glob.glob('/content/drive/MyDrive/project/images_rgb/hornpipe/*.*')\n",
        "jig = glob.glob('/content/drive/MyDrive/project/images_rgb/jig/*.*')\n",
        "polka = glob.glob('/content/drive/MyDrive/project/images_rgb/polka/*.*')\n",
        "reel = glob.glob('/content/drive/MyDrive/project/images_rgb/reel/*.*')\n",
        "slide = glob.glob('/content/drive/MyDrive/project/images_rgb/slide/*.*')\n",
        "\n",
        "data = []\n",
        "labels = []\n",
        "count = 0\n",
        "max = 198\n",
        "for i in hornpipe:   \n",
        "    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n",
        "    target_size= (img_width,img_height))\n",
        "    image=np.array(image)\n",
        "    data.append(image)\n",
        "    labels.append(0)\n",
        "    if count >= max:\n",
        "      break\n",
        "    count+=1\n",
        "count = 0\n",
        "for i in jig:   \n",
        "    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n",
        "    target_size= (img_width,img_height))\n",
        "    image=np.array(image)\n",
        "    data.append(image)\n",
        "    labels.append(1)\n",
        "    if count >= max:\n",
        "      break\n",
        "    count+=1\n",
        "count = 0\n",
        "for i in polka:   \n",
        "    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n",
        "    target_size= (img_width,img_height))\n",
        "    image=np.array(image)\n",
        "    data.append(image)\n",
        "    labels.append(2)\n",
        "    if count >= max:\n",
        "      break\n",
        "    count+=1\n",
        "count = 0\n",
        "for i in reel:   \n",
        "    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n",
        "    target_size= (img_width,img_height))\n",
        "    image=np.array(image)\n",
        "    data.append(image)\n",
        "    labels.append(3)\n",
        "    if count >= max:\n",
        "      break\n",
        "    count+=1\n",
        "count = 0\n",
        "for i in slide:   \n",
        "    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n",
        "    target_size= (img_width,img_height))\n",
        "    image=np.array(image)\n",
        "    data.append(image)\n",
        "    labels.append(4)\n",
        "    if count >= max:\n",
        "      break\n",
        "    count+=1\n",
        "data = np.array(data)\n",
        "labels = np.array(labels)\n",
        "\n",
        "\n",
        "train_ratio = 0.75\n",
        "validation_ratio = 0.15\n",
        "test_ratio = 0.10\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=1 - train_ratio, random_state=seed)\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio), random_state=seed) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwNlPAx1bK6R"
      },
      "source": [
        "*Note, change file paths to where ever the data is stored*\n",
        "- Reads in image files for max (198) number of files per class\n",
        "- Splits data into 75:15:10 train, validation, test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3G8FtTDfZQGA"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.models import Sequential\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "inputs = x_train\n",
        "targets = y_train\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state =seed)\n",
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "fold_no = 1\n",
        "num_classes = 5\n",
        "\n",
        "for train, test in kfold.split(inputs, targets):\n",
        "  model = Sequential([\n",
        "    layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_width, img_height, 3)),\n",
        "    layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "    layers.MaxPooling2D(2,2),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    layers.MaxPooling2D(2,2),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    layers.MaxPooling2D(2,2),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(num_classes)\n",
        "  ])\n",
        "  model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "  epochs=10\n",
        "  history = model.fit(\n",
        "    inputs[train], targets[train],\n",
        "    validation_data= (x_val,y_val),\n",
        "    epochs=epochs\n",
        "  )\n",
        "  scores = model.evaluate(inputs[test], targets[test], verbose=0)\n",
        "  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "  acc_per_fold.append(scores[1] * 100)\n",
        "  loss_per_fold.append(scores[0])\n",
        "\n",
        "  fname = '//content/drive/MyDrive/project/multiclass meter models/k folds/meter_model'+str(fold_no)\n",
        "  model.save(fname)\n",
        "  \n",
        "  y_pred = model.predict(inputs[test])\n",
        "  predicted_categories = tf.argmax(y_pred, axis=1)\n",
        "  true_categories = tf.concat([targets[test]], axis=0)\n",
        "  array = confusion_matrix(predicted_categories, true_categories, normalize=None)\n",
        "  df_cm = pd.DataFrame(array, index = [i for i in ['hornpipe', 'jig', 'polka', 'reel', 'slide']],\n",
        "                    columns = [i for i in ['hornpipe', 'jig', 'polka', 'reel', 'slide']])\n",
        "  plt.figure(figsize = (10,7))\n",
        "  sn.heatmap(df_cm, annot=True)\n",
        "  print('--------------------')\n",
        "  print('for fold:', fold_no)\n",
        "  print(array)\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhDSo6TGdJzJ"
      },
      "source": [
        "- performs 5-fold cross validation on training data\n",
        "- model is a CNN comprising:\n",
        "  - 3 2D convolutional layers\n",
        "  - 3 layers of max pooling\n",
        "  - 2 instances of 20% dropout\n",
        "- completes training of model at each fold, then evaluates each model\n",
        "- displays confusion matrix for each fold\n",
        "- saves the model at each fold so it can be accessed later\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxekUIeFpANE"
      },
      "source": [
        "from tensorflow import keras\n",
        "model = keras.models.load_model('/content/drive/MyDrive/project/multiclass meter models/k folds/meter_model3')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l36LYXmZiMks"
      },
      "source": [
        "loads in the most effective model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gGd32vevb99"
      },
      "source": [
        "checkpoint_filepath = '/content/drive/MyDrive/project/multiclass meter models/training/model_epoch{epoch:02d}-loss{val_loss:.4f}'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fClvkcxiPnk"
      },
      "source": [
        "adds in a calllback metric which saves the weights of the model each time validation loss hits a new low"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-MfEt_WMj0a"
      },
      "source": [
        "epochs=70\n",
        "history = model.fit(\n",
        "  x = x_train, y = y_train,\n",
        "  validation_data= (x_val,y_val),\n",
        "  epochs=epochs, callbacks=[model_checkpoint_callback]\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2I8alKHlW7j"
      },
      "source": [
        "best model is trained on the whole dataset for 70 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4vyrPhIt_bQ"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.8, 1.0])\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.ylim([0, 0.4])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REOIuH8By5bH"
      },
      "source": [
        "the training and validation accuracy and loss are plotted for the model per epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULvZMV5eGUiH"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "y_pred = model.predict(x_test)\n",
        "predicted_categories = tf.argmax(y_pred, axis=1)\n",
        "true_categories = tf.concat([y_test], axis=0)\n",
        "array = confusion_matrix(predicted_categories, true_categories, normalize=None)\n",
        "df_cm = pd.DataFrame(array, index = [i for i in ['hornpipe', 'jig', 'polka', 'reel', 'slide']],\n",
        "                  columns = [i for i in ['hornpipe', 'jig', 'polka', 'reel', 'slide']])\n",
        "plt.figure(figsize = (10,7))\n",
        "sn.heatmap(df_cm, annot=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udKuvZORzN09"
      },
      "source": [
        "confusion matrix plotted for data based on results of test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEsAESvsE6cR"
      },
      "source": [
        "checkpoint_path = '/content/drive/MyDrive/project/multiclass meter models/training/model_epoch53-loss0.0447'\n",
        "model.load_weights(checkpoint_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zF9d7kAzwxe"
      },
      "source": [
        "the weights of the model with minimised validation loss were loaded in to evaluate this"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lliBm3BmHvI2"
      },
      "source": [
        "y_pred = model.predict(x_test)\n",
        "predicted_categories = tf.argmax(y_pred, axis=1)\n",
        "true_categories = tf.concat([y_test], axis=0)\n",
        "array = confusion_matrix(predicted_categories, true_categories, normalize='true')\n",
        "df_cm = pd.DataFrame(array, index = [i for i in ['hornpipe', 'jig', 'polka', 'reel', 'slide']],\n",
        "                  columns = [i for i in ['hornpipe', 'jig', 'polka', 'reel', 'slide']])\n",
        "plt.figure(figsize = (10,7))\n",
        "sn.heatmap(df_cm, annot=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Izh4mP6Bz9S1"
      },
      "source": [
        "confusion matrix plotted for weight adjusted model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eCdTXnCQUtS",
        "outputId": "38d019de-cc6d-4931-b369-fe6b931fee10"
      },
      "source": [
        "scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 99.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDl6ebfDIzMM"
      },
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "from PIL import Image\n",
        "plot_model(model, to_file='multi_meter_model_diagram.png', show_shapes=True, show_layer_names=True)\n",
        "display(Image.open('multi_meter_model_diagram.png'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}